{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Implementation of the scalar object for autodifferentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from util import assert_close\n",
    "    import operators\n",
    "    from autodiff import FunctionBase, Variable, History\n",
    "except:\n",
    "    from .util import assert_close\n",
    "    from . import operators    \n",
    "    from .autodiff import FunctionBase, Variable, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_difference(f, *vals, arg=0, epsilon=1e-6):\n",
    "    r\"\"\"\n",
    "    Computes an approximation to the derivative of `f` with respect to one arg.\n",
    "\n",
    "    See :doc:`derivative` or https://en.wikipedia.org/wiki/Finite_difference for more details.\n",
    "\n",
    "    Args:\n",
    "       f : arbitrary function from n-args to one value\n",
    "       *vals (floats): n-float values :math:`x_1 \\ldots x_n`\n",
    "       arg (int): the number :math:`i` of the arg to compute the derivative\n",
    "       epsilon (float): a small constant\n",
    "\n",
    "    Returns:\n",
    "       float : An approximation of :math:`f'_i(x_1, \\ldots, x_n)`\n",
    "    \"\"\"\n",
    "    vals1 = list(vals)\n",
    "    vals1[arg] += epsilon\n",
    "    vals2 = list(vals)\n",
    "    vals2[arg] -= epsilon\n",
    "    return (f(*vals1) - f(*vals2))/ (2.* epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scalar(Variable):\n",
    "    \"\"\"\n",
    "    A reimplementation of scalar values for autodifferentiation\n",
    "    tracking.  Scalar Variables behave as close as possible to standard\n",
    "    Python numbers while also tracking the operations that led to the\n",
    "    numbers creation. They can only be manipulated by\n",
    "    :class:`ScalarFunction`.\n",
    "\n",
    "    Attributes:\n",
    "        data (float): The wrapped scalar value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, v, back=History(), name=None):\n",
    "        super().__init__(back, name=name)\n",
    "        self.data = v\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Scalar(%f)\" % self.data\n",
    "\n",
    "    def __mul__(self, b):\n",
    "        return Mul.apply(self, b)\n",
    "\n",
    "    def __truediv__(self, b):\n",
    "        return Mul.apply(self, Inv.apply(b))\n",
    "\n",
    "    def __add__(self, b):\n",
    "        return Add.apply(self, b)\n",
    "        \n",
    "    def __lt__(self, b):\n",
    "        return LT.apply(self, b)\n",
    "        \n",
    "    def __gt__(self, b):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __sub__(self, b):\n",
    "        return Add.apply(self, Neg.apply(b))\n",
    "\n",
    "    def __neg__(self):\n",
    "        return Neg.apply(self)\n",
    "        \n",
    "    def log(self):\n",
    "        return Log.apply(self)\n",
    "        \n",
    "    def sigmoid(self):\n",
    "        return Sigmoid.apply(self)\n",
    "        \n",
    "    def relu(self):\n",
    "        return ReLU.apply(self)\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarFunction(FunctionBase):\n",
    "    \"A function that processes and produces Scalar variables.\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, *inputs):\n",
    "        \"\"\"Args:\n",
    "\n",
    "           ctx (:class:`Context`): A special container object to save\n",
    "                                   any information that may be needed for the call to backward.\n",
    "           *inputs (list of numbers): Numerical arguments.\n",
    "\n",
    "        Returns:\n",
    "            number : The computation of the function f.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ctx (Context): A special container object holding any information saved during in the corresponding `forward` call.\n",
    "            d_output (number):\n",
    "        Returns:\n",
    "            numbers : The computation of the derive function f' for each inputs times `d_output`.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # checks.\n",
    "    variable = Scalar\n",
    "    data_type = float\n",
    "\n",
    "    @staticmethod\n",
    "    def data(a):\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "class Add(ScalarFunction):\n",
    "    \"Implements additions\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        return operators.add(a, b)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output) -> Tuple:\n",
    "        return (d_output, d_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(ScalarFunction):\n",
    "    \"Implements log\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        ctx.save_for_backward(a)\n",
    "        return operators.log(a)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        a = ctx.saved_values\n",
    "        return (\n",
    "            operators.log_back(a, d_output), \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class LT(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        return 1.0 if a < b else 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        return (0.0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "To implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a, b):\n",
    "        ctx.save_for_backward(a, b)\n",
    "        return operators.mul(a, b)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        a, b = ctx.saved_values\n",
    "        return (\n",
    "            operators.mul(d_output, b), \n",
    "            operators.mul(d_output, a)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inv(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        ctx.save_for_backward(a)\n",
    "        return 1./a\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        a = ctx.saved_values\n",
    "        return (\n",
    "            operators.neg(d_output) / operators.mul(a, a), \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neg(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        return operators.neg(a)\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        return (\n",
    "            operators.neg(d_output),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        s = operators.sigmoid(a)\n",
    "        ctx.save_for_backward(s)\n",
    "        return s\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        s = ctx.saved_values\n",
    "        return (\n",
    "            operators.mul(d_output, operators.mul(s, 1 - s)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        ctx.save_for_backward(a)\n",
    "        return operators.relu(a)\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        a = ctx.saved_values\n",
    "        return (\n",
    "            operators.relu_back(a, d_output),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(ScalarFunction):\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        e = operators.exp(a)\n",
    "        ctx.save_for_backward(e)\n",
    "        return e\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, d_output):\n",
    "        e = ctx.saved_values\n",
    "        return (\n",
    "            operators.mul(e, d_output),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_check(f, *scalars):\n",
    "\n",
    "    for x in scalars:\n",
    "        x.requires_grad_(True)\n",
    "    out = f(*scalars)\n",
    "    out.backward()\n",
    "\n",
    "    vals = [v for v in scalars]\n",
    "\n",
    "    for i, x in enumerate(scalars):\n",
    "        check = central_difference(f, *vals, arg=i)\n",
    "        print(x.derivative, check)\n",
    "        assert_close(x.derivative, check.data)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:light,ipynb"
  },
  "kernelspec": {
   "display_name": "minitorch",
   "language": "python",
   "name": "minitorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
